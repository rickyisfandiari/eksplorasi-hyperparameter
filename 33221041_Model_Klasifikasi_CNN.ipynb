{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSRFTqbOYAUY"
      },
      "source": [
        "# **Model Klasifikasi Data Gambar Fashion-MNIST Menggunakan CNN**\n",
        "\n",
        "Penelitian ini akan membuat klasifikasi terhadap data gambar menggunakan metode CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcMYWwb9YjMe"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Dataset yang digunakan adalah Fashion-MNIST yang bersumber dari Keras yaitu https://keras.io/api/datasets/fashion_mnist. Dataset tersebut berupa kumpulan data gambar yang memiliki 60.000 gambar pelatihan (training) dan 10.000 gambar pengujian (testing), di mana setiap gambar abu-abu berukuran 28x28 pixel dengan label yang terdiri dari 10 kelas. Fashion-MNIST berfungsi sebagai pengganti langsung dataset MNIST asli untuk membuat tolok ukur algoritma machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HNLKc5fX9Nw"
      },
      "outputs": [],
      "source": [
        "# Import semua library yang dibutuhkan.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Peringatan untuk berhenti.\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEhh_8kbX28C"
      },
      "outputs": [],
      "source": [
        "# Mengambil dataset \"Fashion-MNIST\".\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzFGd9ukZe65"
      },
      "outputs": [],
      "source": [
        "# Solusi terbaik untuk menormalkan nilai input adalah mengubahnya menjadi\n",
        "# skala 0 hingga 1. Setiap elemen dalam dataset ini memiliki nilai pixel 0 hingga 255,\n",
        "# jadi peneliti akan membuat ulang skala dari nilai-nilai tersebut.\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIHL1p4FX9U3"
      },
      "outputs": [],
      "source": [
        "# Inisiasi nama kelas.\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svbfCKBOYp-b"
      },
      "outputs": [],
      "source": [
        "# Informasi jumlah kelas dan image pada data pelatihan dan data pengujian.\n",
        "print(\"Shape of Training Image Data: \" + str(x_train.shape))\n",
        "print(\"Shape of Training Class Data: \" + str(y_train.shape))\n",
        "print(\"Shape of Test Image Data: \" + str(x_test.shape))\n",
        "print(\"Shape of Test Class Data: \" + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym0c8NpnY50k"
      },
      "outputs": [],
      "source": [
        "# Visualisasi 20 gambar pertama dari data pelatihan.\n",
        "plt.figure(figsize=(15,15))\n",
        "for i in range(20):\n",
        "    plt.subplot(4,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[y_train[i]])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9KfNXIuZp0Y"
      },
      "outputs": [],
      "source": [
        "# Visualisasi gambar dengan nilai pixel.\n",
        "index = 0\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.imshow(x_train[index], cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[y_train[index]])\n",
        "plt.colorbar()\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_xticks(np.arange(-.5, 28, 1))\n",
        "ax.set_yticks(np.arange(-.5, 28, 1))\n",
        "ax.set_xticklabels(np.arange(0, 29, 1))\n",
        "ax.set_yticklabels(np.arange(0, 29, 1))\n",
        "ax.xaxis.tick_top()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrT53xeSbDHe"
      },
      "source": [
        "## Pemodelan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_RzUtykbIbr"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan model menggunakan library Keras.\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Dimulai dengan layer konvolusi yang akan mengekstrak fitur dari\n",
        "# gambar input dengan menggeser filter konvolusi di atas gambar input,\n",
        "# kemudian menghasilkan peta fitur.\n",
        "model.add(\n",
        "    tf.keras.layers.Conv2D(   # Model CNN.\n",
        "        filters=128,   # Banyaknya filter yang akan kita pelajari.\n",
        "        kernel_size=(3, 3),   # Ukuran peta fitur yang akan ada di atas gambar.\n",
        "        strides=(1, 1),   # Bagaimana peta fitur bergeser di seluruh gambar.\n",
        "        padding='valid',   # Padding tidak digunakan.\n",
        "        activation='relu',   # Fungsi aktivasi menggunakan ReLU.\n",
        "        input_shape=(28, 28, 1)   # Bentuk pixel input yang diharapkan untuk layer ini.\n",
        "    )\n",
        ")\n",
        "\n",
        "# Layer berikutnya yang ditambahkan adalah layer Maxpooling.\n",
        "# Hal ini mengurangi dimensi setiap fitur dan mengurangi jumlah\n",
        "# parameter model untuk belajar, sehingga mempersingkat waktu training.\n",
        "model.add(\n",
        "    tf.keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2),   # Ukuran fitur yang dipetakan.\n",
        "        strides=(2, 2)   # Pergeserannya pada fitur.\n",
        "    )\n",
        ")\n",
        "          \n",
        "# Mnambahkan layer dropout untuk melawan overfitting dan membuat\n",
        "# model mempelajari beberapa representasi dari data yang sama\n",
        "# dengan menonaktifkan neuron secara acak dalam fase belajar.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25   # Menonaktifkan 25% neuron secara acak.\n",
        "    )\n",
        ")\n",
        "\n",
        "# Output dari layer sebelumnya adalah tensor 3D dan harus\n",
        "# diubah ke vektor 1D sebelum diberikan ke dense layer.\n",
        "model.add(\n",
        "    tf.keras.layers.Flatten()\n",
        ")\n",
        "\n",
        "# Dense layer yang saling terhubung ditambahkan untuk\n",
        "# memetakan fitur turunan ke kelas yang diperlukan.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=512,   # Hidden unit.\n",
        "        activation='relu'   # Fungsi aktivasi menggunakan ReLU.\n",
        "    )\n",
        ")\n",
        "\n",
        "# Lapisan terakhir dengan 10 output dan fungsi aktivasi Softmax.\n",
        "# Fungsi aktivasi Softmax dapat digunakan untuk menghitung output\n",
        "# berdasarkan probabilitas. Setiap kelas diberi probabilitas dan\n",
        "# kelas dengan probabilitas maksimum adalah output dari model.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=10,   # Hidden unit.\n",
        "        activation='softmax'   # Fungsi aktivasi menggunakan Softmax.\n",
        "    )\n",
        ")\n",
        "\n",
        "# Membangun model.\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.sparse_categorical_crossentropy,   # Loss function menggunakan Sparse Categorical Crossentropy.\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),   # Optimizer function menggunakan Adam.\n",
        "    metrics=['accuracy']   # Metrik akurasi.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlyTxea073WL"
      },
      "outputs": [],
      "source": [
        "# Ringkasan struktur model.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIF9upctQyy3"
      },
      "outputs": [],
      "source": [
        "# Visualisasi struktur model.\n",
        "tf.keras.utils.plot_model(model, to_file='struktur_model_cnn.png', show_shapes=True, show_layer_names=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZpd_vWLcfU9"
      },
      "source": [
        "## Pelatihan dan Validasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNWdTFc3cilQ"
      },
      "outputs": [],
      "source": [
        "# Menambahkan dimensi warna kosong untuk CNN.\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Melatih CNN menggunakan data pelatihan.\n",
        "history = model.fit(\n",
        "    \n",
        "      # Data pelatihan: Fitur (gambar) dan kelas.\n",
        "      x_train, y_train,\n",
        "                    \n",
        "      # Jumlah sampel yang harus dikerjakan sebelum memperbarui\n",
        "      # parameter model internal melalui back propagation.\n",
        "      batch_size=256,\n",
        "\n",
        "      # Jumlah epoch untuk iterasi pada seluruh data pelatihan.\n",
        "      epochs=10,\n",
        "\n",
        "      # Model akan memisahkan data pelatihan dan data validasi.\n",
        "      # Dari dataset pelatihan yang ada, 80% akan digunakan untuk pelatihan\n",
        "      # dan 20% akan digunakan untuk validasi untuk mengevaluasi nilai\n",
        "      # loss dan nilai akurasi model di akhir setiap epoch.\n",
        "      validation_split=0.2,\n",
        "\n",
        "      verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7FI8OgXe00J"
      },
      "source": [
        "## Pengujian dan Evaluasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYRQQIKhexMe"
      },
      "outputs": [],
      "source": [
        "# Melihat hasil prediksi model untuk data pengujian, kemudian\n",
        "# mengevaluasi nilai loss dan nilai akurasi model di akhir setiap epoch.\n",
        "predicted_classes = np.argmax(model.predict(x_test),axis=1)\n",
        "print(classification_report(y_test, predicted_classes, target_names=class_names, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFXEvBB9hvor"
      },
      "outputs": [],
      "source": [
        "# Melihat data pengujian yang salah diklasifikasikan.\n",
        "incorrect = np.nonzero(predicted_classes!=y_test)[0]\n",
        "\n",
        "# Menampilkan 8 gambar pertama yang salah diklasifikasikan dari data pengujian.\n",
        "plt.figure(figsize=(15, 8))\n",
        "for j, incorrect in enumerate(incorrect[0:8]):\n",
        "    plt.subplot(2, 4, j+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[incorrect].reshape(28, 28), cmap=\"Reds\")\n",
        "    plt.title(\"Predicted: {}\".format(class_names[predicted_classes[incorrect]]))\n",
        "    plt.xlabel(\"Actual: {}\".format(class_names[y_test[incorrect]]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "33221041-Model-Klasifikasi-CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}